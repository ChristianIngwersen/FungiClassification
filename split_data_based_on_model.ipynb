{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and predict model on all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cin/miniconda3/envs/fungidev/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "100%|██████████| 36393/36393 [25:40<00:00, 23.62it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from fungi_classification import get_transforms\n",
    "from  tqdm import tqdm\n",
    "\n",
    "\n",
    "data_dir = \"/data/AIDatasets/fungi/DF20M/\"\n",
    "best_trained_model = \"/home/cin/Projects/FungiClassification/saved_models/DF20M-EfficientNet-B0_best_accuracy.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_classes = 183\n",
    "model = EfficientNet.from_name('efficientnet-b0', num_classes=n_classes)\n",
    "checkpoint = torch.load(best_trained_model)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device).eval()\n",
    "\n",
    "\n",
    "transform = get_transforms(\"valid\")\n",
    "im_paths = sorted(glob.glob(data_dir + \"*.JPG\"))\n",
    "pred_labels = []\n",
    "\n",
    "for im_path in tqdm(im_paths):\n",
    "    im = Image.open(im_path)\n",
    "    im = transform(image=np.asarray(im))\n",
    "    im = im[\"image\"].to(device).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_labels.append(model(im).argmax(1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_sort_patmjen.npy\", \"wb\") as fp:\n",
    "    np.savez(fp, im_names=im_paths, pred_labels=pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cin/miniconda3/envs/fungidev/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "  1%|          | 223/36393 [00:07<19:17, 31.25it/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 1.78 GiB (GPU 0; 7.80 GiB total capacity; 4.11 GiB already allocated; 1.72 GiB free; 5.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/cin/Projects/FungiClassification/split_data_based_on_model.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.5.15.210/home/cin/Projects/FungiClassification/split_data_based_on_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m c \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.5.15.210/home/cin/Projects/FungiClassification/split_data_based_on_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.5.15.210/home/cin/Projects/FungiClassification/split_data_based_on_model.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     pred_labels\u001b[39m.\u001b[39mappend(model(im)\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/efficientnet_pytorch/model.py:314\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[39m\"\"\"EfficientNet's forward function.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m   Calls extract_features to extract features, applies final linear layer, and returns logits.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m    Output of this model after processing.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m# Convolution layers\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(inputs)\n\u001b[1;32m    315\u001b[0m \u001b[39m# Pooling and final linear layer\u001b[39;00m\n\u001b[1;32m    316\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_avg_pooling(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/efficientnet_pytorch/model.py:296\u001b[0m, in \u001b[0;36mEfficientNet.extract_features\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[39mif\u001b[39;00m drop_connect_rate:\n\u001b[1;32m    295\u001b[0m         drop_connect_rate \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(idx) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocks)  \u001b[39m# scale drop connect_rate\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     x \u001b[39m=\u001b[39m block(x, drop_connect_rate\u001b[39m=\u001b[39;49mdrop_connect_rate)\n\u001b[1;32m    298\u001b[0m \u001b[39m# Head\u001b[39;00m\n\u001b[1;32m    299\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_swish(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_conv_head(x)))\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/efficientnet_pytorch/model.py:107\u001b[0m, in \u001b[0;36mMBConvBlock.forward\u001b[0;34m(self, inputs, drop_connect_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_conv(inputs)\n\u001b[1;32m    106\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bn0(x)\n\u001b[0;32m--> 107\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_swish(x)\n\u001b[1;32m    109\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_depthwise_conv(x)\n\u001b[1;32m    110\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bn1(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/efficientnet_pytorch/utils.py:80\u001b[0m, in \u001b[0;36mMemoryEfficientSwish.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m SwishImplementation\u001b[39m.\u001b[39;49mapply(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/fungidev/lib/python3.9/site-packages/efficientnet_pytorch/utils.py:67\u001b[0m, in \u001b[0;36mSwishImplementation.forward\u001b[0;34m(ctx, i)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(ctx, i):\n\u001b[0;32m---> 67\u001b[0m     result \u001b[39m=\u001b[39m i \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49msigmoid(i)\n\u001b[1;32m     68\u001b[0m     ctx\u001b[39m.\u001b[39msave_for_backward(i)\n\u001b[1;32m     69\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 1.78 GiB (GPU 0; 7.80 GiB total capacity; 4.11 GiB already allocated; 1.72 GiB free; 5.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from fungi_classification import get_transforms\n",
    "from  tqdm import tqdm\n",
    "\n",
    "\n",
    "data_dir = \"/data/AIDatasets/fungi/DF20M/\"\n",
    "best_trained_model = \"/home/cin/Projects/FungiClassification/saved_models/DF20M-EfficientNet-B0_best_loss.pth\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "n_classes = 183\n",
    "model = EfficientNet.from_name('efficientnet-b0', num_classes=n_classes)\n",
    "checkpoint = torch.load(best_trained_model)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device).eval()\n",
    "\n",
    "\n",
    "transform = get_transforms(\"valid\")\n",
    "im_paths = sorted(glob.glob(data_dir + \"*.JPG\"))\n",
    "pred_labels = []\n",
    "\n",
    "batch_sz = 32\n",
    "c = 0\n",
    "b_ims = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for im_path in tqdm(im_paths):\n",
    "        im = Image.open(im_path)\n",
    "        im = transform(image=np.asarray(im))\n",
    "        b_ims.append(im[\"image\"])\n",
    "        c+=1\n",
    "        if c == batch_sz:\n",
    "            im = torch.stack(b_ims).to(device)\n",
    "            c = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_labels.append(model(im).argmax(1).cpu())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  2, 115, 115, 138,  78,  56, 138, 130,  15, 105,   1, 119,   2,   2,\n",
       "        107, 116, 107,  90,  83, 163,   0, 107,  10,   0,   0, 163,   0,  53,\n",
       "         56, 107,  86,   2,   2, 102, 107,   2, 163,   0,   0,   0,   2,   2,\n",
       "          2,  96,   2,  86,   2, 107,   2,   2, 110,  79, 114,   2,  82,   2,\n",
       "          2, 171,   1, 107,   0,   2,   2,   2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    o = model(im)\n",
    "o.argmax(1).cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move images to new dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "out_dir = \"/home/cin/Projects/FungiClassification/saved_models/sort_ims\"\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    for i in range(183):\n",
    "        os.mkdir(os.path.join(out_dir, str(i)))\n",
    "\n",
    "for im_path, label in zip(im_paths, pred_labels):\n",
    "    shutil.copyfile(im_path, os.path.join(out_dir, label, os.path.basename(im_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sort_ims.jpg'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(out_dir+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('fungidev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d26364ba304de4e9b7aac4ea2b13eadfdda35ec8e6579037264d9816ad76f19c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
